{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: (1048576, 2)\n",
      "[7.0583777 3.7767043]\n",
      "[26.657406]\n"
     ]
    }
   ],
   "source": [
    "# Create a training set of 1024 examples.\n",
    "# For instance, side lengths between 0 and 10.\n",
    "np.random.seed(509)  # Fix the random state for reproducibility\n",
    "num_samples = 2**20\n",
    "x_train = np.random.uniform(low=0, high=10, size=(num_samples, 2)).astype(np.float32)\n",
    "y_train = np.expand_dims(np.prod(x_train, axis=1), axis=-1)  # area = side1 * side2\n",
    "\n",
    "# samples\n",
    "print(f\"Data: {x_train.shape}\")\n",
    "print(x_train[1])\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m4\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m2\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def square_activation(x):\n",
    "    return tf.math.pow(x, 2)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(2, activation=square_activation, input_shape=(2,), use_bias=False),\n",
    "    Dense(1, use_bias=False)\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer=keras.optimizers.Adam(0.1),\n",
    "    metrics=['mae']  # Mean Absolute Error for additional monitoring\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 715.2131 - mae: 12.1323 - learning_rate: 0.1000\n",
      "Epoch 2/700\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10.0334 - mae: 2.0326 - learning_rate: 0.1000\n",
      "Epoch 3/700\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.7672e-05 - mae: 0.0021 - learning_rate: 0.1000\n",
      "Epoch 4/700\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6108e-11 - mae: 5.9704e-06 - learning_rate: 0.1000\n",
      "Epoch 5/700\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.9763e-11 - mae: 5.8064e-06 - learning_rate: 0.1000\n",
      "Epoch 6/700\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7160e-11 - mae: 5.1737e-06 - learning_rate: 0.1000\n",
      "Epoch 7/700\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.2379e-11 - mae: 4.3911e-06 - learning_rate: 0.1000\n",
      "Epoch 8/700\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3354e-11 - mae: 3.2920e-06 - learning_rate: 0.0500\n",
      "Epoch 9/700\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3150e-11 - mae: 3.2767e-06 - learning_rate: 0.0500\n",
      "Epoch 10/700\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3850e-11 - mae: 3.3338e-06 - learning_rate: 0.0500\n",
      "Epoch 11/700\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3557e-11 - mae: 3.3131e-06 - learning_rate: 0.0250\n",
      "Epoch 12/700\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.2885e-11 - mae: 3.2506e-06 - learning_rate: 0.0250\n",
      "Epoch 13/700\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.2814e-11 - mae: 3.2451e-06 - learning_rate: 0.0250\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=700,\n",
    "    batch_size=2**12,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, monitor='mae', min_delta=0.001),\n",
    "               tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, monitor='mae')],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "Input sides: [[3. 4.]]\n",
      "Predicted area: 12.000002\n"
     ]
    }
   ],
   "source": [
    "# Test with a known example: side lengths 3 and 4 (expected area = 12)\n",
    "test_input = np.array([[3, 4]], dtype=np.float32)\n",
    "predicted_area = model.predict(test_input)\n",
    "print(\"Input sides:\", test_input)\n",
    "print(\"Predicted area:\", predicted_area[0, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.6046531,  0.4209206],\n",
      "       [-1.11246  , -0.7744229]], dtype=float32)]\n",
      "[array([[ 0.37166297],\n",
      "       [-0.76694095]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# print the weights\n",
    "for layer in model.layers:\n",
    "    print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Weights for the First Layer (Dense with square activation) ===\n",
      "W1:\n",
      " [array([[-0.6046531,  0.4209206],\n",
      "       [-1.11246  , -0.7744229]], dtype=float32)]\n",
      "\n",
      "=== Weights for the Second Layer (Output Dense Layer) ===\n",
      "W2:\n",
      " [array([[ 0.37166297],\n",
      "       [-0.76694095]], dtype=float32)]\n",
      "\n",
      "Input example: [[3. 4.]]\n",
      "\n",
      "Step 1: Compute z1 (linear output of first layer):\n",
      "z1 = [[[-6.2637997 -1.8349297]]]\n",
      "\n",
      "Step 2: Apply square activation (a1 = z1^2 elementwise):\n",
      "a1 = [[[39.235188  3.366967]]]\n",
      "\n",
      "Step 3: Compute final output (a1 dot W2 + b2):\n",
      "Output = [[[[12.000002]]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\n",
      "Output from model.predict: [[12.000002]]\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Weights for the First Layer (Dense with square activation) ===\")\n",
    "W1 = model.layers[0].get_weights()\n",
    "print(\"W1:\\n\", W1)\n",
    "\n",
    "print(\"\\n=== Weights for the Second Layer (Output Dense Layer) ===\")\n",
    "W2 = model.layers[1].get_weights()\n",
    "print(\"W2:\\n\", W2)\n",
    "\n",
    "# Now, let's manually calculate the output for an example input.\n",
    "# We choose an input of two side lengths. For example:\n",
    "input_example = np.array([[3, 4]], dtype=np.float32)  # shape (1,2)\n",
    "print(\"\\nInput example:\", input_example)\n",
    "\n",
    "# ---- Step 1: First Layer Linear Combination ----\n",
    "# Compute z1 = input * W1 + b1\n",
    "z1 = np.dot(input_example, W1)\n",
    "print(\"\\nStep 1: Compute z1 (linear output of first layer):\")\n",
    "print(\"z1 =\", z1)\n",
    "\n",
    "# ---- Step 2: Apply the Squaring Activation ----\n",
    "# Our custom activation squares each element: a1 = z1^2 (elementwise)\n",
    "a1 = np.power(z1, 2)\n",
    "print(\"\\nStep 2: Apply square activation (a1 = z1^2 elementwise):\")\n",
    "print(\"a1 =\", a1)\n",
    "\n",
    "# ---- Step 3: Second Layer Calculation ----\n",
    "# Compute the final output: output = a1 * W2 + b2\n",
    "output_manual = np.dot(a1, W2)\n",
    "print(\"\\nStep 3: Compute final output (a1 dot W2 + b2):\")\n",
    "print(\"Output =\", output_manual)\n",
    "\n",
    "# Compare with model.predict\n",
    "output_model = model.predict(input_example)\n",
    "print(\"\\nOutput from model.predict:\", output_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
